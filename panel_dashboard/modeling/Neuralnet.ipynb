{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00c932f-585c-4efa-a4ba-04812d17cced",
   "metadata": {},
   "source": [
    "set seeds for reproducible results then import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a30c92f-a14c-4ef7-8723-34101c2380a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 10:48:58.158433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# from numpy.random import seed\n",
    "# seed(1)\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(2)\n",
    "\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e5fda7-1a73-4584-8af9-1c2f34aa0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "#from yahoo_fin.stock_info import get_data\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278db87f-540c-4d6d-bb58-cd9bc8c2f229",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd137c6-1625-4288-b3c7-67f22040bf72",
   "metadata": {},
   "source": [
    "## *Data has been preprocessed*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02c345-5d22-41df-82aa-240e5e5550f3",
   "metadata": {},
   "source": [
    "\n",
    "* Load the test/train datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5eaa51-b5de-48a7-ac70-ef41639dcfad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the portfolios being used\n",
    "portfolios = ['conservative', 'balanced', 'growth', 'aggressive','alternative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984dcb3e-8ad7-4c20-8673-4be088f9cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_train_full and X_test_full\n",
    "X_train_full_conservative = pd.read_csv(Path(\"./data/X_train_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_conservative = pd.read_csv(Path(\"./data/X_test_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_balanced = pd.read_csv(Path(\"./data/X_train_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_balanced = pd.read_csv(Path(\"./data/X_test_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_growth = pd.read_csv(Path(\"./data/X_train_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_growth = pd.read_csv(Path(\"./data/X_test_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_aggressive = pd.read_csv(Path(\"./data/X_train_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_aggressive = pd.read_csv(Path(\"./data/X_test_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_alternative = pd.read_csv(Path(\"./data/X_train_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_alternative = pd.read_csv(Path(\"./data/X_test_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "#load y_train and y_test\n",
    "y_train_conservative = pd.read_csv(Path(\"./data/y_train_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "y_test_conservative = pd.read_csv(Path(\"./data/y_test_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "\n",
    "y_train_balanced = pd.read_csv(Path(\"./data/y_train_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "y_test_balanced = pd.read_csv(Path(\"./data/y_test_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "\n",
    "y_train_growth = pd.read_csv(Path(\"./data/y_train_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "y_test_growth = pd.read_csv(Path(\"./data/y_test_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "\n",
    "y_train_aggressive = pd.read_csv(Path(\"./data/y_train_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "y_test_aggressive = pd.read_csv(Path(\"./data/y_test_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "\n",
    "y_train_alternative = pd.read_csv(Path(\"./data/y_train_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "y_test_alternative = pd.read_csv(Path(\"./data/y_test_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True).values.ravel()\n",
    "\n",
    "datafiles_full = {'conservative': [X_train_full_conservative,\n",
    "                              X_test_full_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_full_balanced,\n",
    "                              X_test_full_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_full_growth,\n",
    "                              X_test_full_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_full_aggressive,\n",
    "                              X_test_full_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_full_alternative,\n",
    "                              X_test_full_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e29412-4965-4d1e-b95c-4c4f78cd2334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load X_train_reduced and X_test_reduced\n",
    "X_train_reduced_conservative = pd.read_csv(Path(\"./data/X_train_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_conservative = pd.read_csv(Path(\"./data/X_test_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_balanced = pd.read_csv(Path(\"./data/X_train_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_balanced = pd.read_csv(Path(\"./data/X_test_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_growth = pd.read_csv(Path(\"./data/X_train_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_growth = pd.read_csv(Path(\"./data/X_test_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_aggressive = pd.read_csv(Path(\"./data/X_train_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_aggressive = pd.read_csv(Path(\"./data/X_test_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_alternative = pd.read_csv(Path(\"./data/X_train_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_alternative = pd.read_csv(Path(\"./data/X_test_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "datafiles_reduced = {'conservative': [X_train_reduced_conservative,\n",
    "                              X_test_reduced_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_reduced_balanced,\n",
    "                              X_test_reduced_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_reduced_growth,\n",
    "                              X_test_reduced_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_reduced_aggressive,\n",
    "                              X_test_reduced_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_reduced_alternative,\n",
    "                              X_test_reduced_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3bc2b6-819e-49ca-9794-dee3868329e8",
   "metadata": {},
   "source": [
    "## Use Hyperband to determine optimal parameters for layer units, layer activations and optimizer learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eedade-be0f-429a-b3f5-cfa328d57a01",
   "metadata": {},
   "source": [
    "### Run for full feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c528993-79a0-44ed-b49b-74b59010475a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 10:49:03.833857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now running tuner search for conservative\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for conservative are:\n",
      "units1 10\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 relu\n",
      "learning_rate 0.01\n",
      "now running tuner search for balanced\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for balanced are:\n",
      "units1 30\n",
      "units2 3\n",
      "activation1 relu\n",
      "activation2 relu\n",
      "learning_rate 0.0001\n",
      "now running tuner search for growth\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for growth are:\n",
      "units1 36\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 tanh\n",
      "learning_rate 0.01\n",
      "now running tuner search for aggressive\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for aggressive are:\n",
      "units1 28\n",
      "units2 7\n",
      "activation1 relu\n",
      "activation2 relu\n",
      "learning_rate 0.01\n",
      "now running tuner search for alternative\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for alternative are:\n",
      "units1 18\n",
      "units2 9\n",
      "activation1 relu\n",
      "activation2 relu\n",
      "learning_rate 0.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_full = pd.DataFrame()\n",
    "X_scaler = StandardScaler()\n",
    "for p in portfolios:\n",
    "    X_train = datafiles_full[p][0]\n",
    "    X_test = datafiles_full[p][1]\n",
    "    y_train = datafiles_full[p][2]\n",
    "    y_test = datafiles_full[p][3]\n",
    "    \n",
    "    scaler = X_scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    number_input_features = 18\n",
    "    def model_builder(hp):\n",
    "\n",
    "        hp_units = hp.Int('units', min_value=6, max_value=36, step=2)\n",
    "        hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "        hp_units2 = hp.Int('units2', min_value=3, max_value=18, step=2)\n",
    "        hp_activation2 = hp.Choice('activation2', values=['relu', 'tanh'])\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=hp_units, input_dim=number_input_features, activation=hp_activation))\n",
    "        model.add(Dense(units=hp_units2, activation=hp_activation2))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    tuner = kt.Hyperband(model_builder, objective='val_accuracy',\n",
    "                 max_epochs=100,\n",
    "                 factor=3,\n",
    "                 directory='./hp',\n",
    "                 project_name=f\"hp_{p}\")\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    print(f\"now running tuner search for {p}\")\n",
    "    tuner.search(X_train_scaled, y_train, epochs=100, validation_split=0.2, callbacks=[stop_early], verbose=0)\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_unit1 = best_hps.get('units')\n",
    "    best_unit2 = best_hps.get('units2') \n",
    "    best_activation1 =  best_hps.get('activation')\n",
    "    best_activation2 = best_hps.get('activation2')\n",
    "    best_learning_rate = best_hps.get('learning_rate')\n",
    "\n",
    "    best_dict = {'units1': best_unit1,\n",
    "                 'units2': best_unit2,\n",
    "                 'activation1': best_activation1,\n",
    "                 'activation2': best_activation2,\n",
    "                 'learning_rate': best_learning_rate}\n",
    "    \n",
    "    print(f\"best values for {p} are:\")\n",
    "    for k,v in best_dict.items():\n",
    "        print(k, v)\n",
    "        \n",
    "    best_parameters = pd.DataFrame.from_dict(best_dict, orient='index', columns=[f\"{p}\"])\n",
    "    results_full = pd.concat([results_full, best_parameters], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2c569-b222-4730-ba31-11d57473fe08",
   "metadata": {},
   "source": [
    "### Run for reduced feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdfef671-174c-4c85-bb46-8efd2906ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now running tuner search for conservative\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for conservative are:\n",
      "units1 26\n",
      "units2 3\n",
      "activation1 relu\n",
      "activation2 tanh\n",
      "learning_rate 0.01\n",
      "now running tuner search for balanced\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for balanced are:\n",
      "units1 32\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 tanh\n",
      "learning_rate 0.01\n",
      "now running tuner search for growth\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for growth are:\n",
      "units1 36\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 tanh\n",
      "learning_rate 0.001\n",
      "now running tuner search for aggressive\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for aggressive are:\n",
      "units1 34\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 relu\n",
      "learning_rate 0.01\n",
      "now running tuner search for alternative\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for alternative are:\n",
      "units1 30\n",
      "units2 3\n",
      "activation1 relu\n",
      "activation2 tanh\n",
      "learning_rate 0.01\n"
     ]
    }
   ],
   "source": [
    "X_scaler = StandardScaler()\n",
    "results_reduced = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    X_train = datafiles_reduced[p][0]\n",
    "    X_test = datafiles_reduced[p][1]\n",
    "    y_train = datafiles_reduced[p][2]\n",
    "    y_test = datafiles_reduced[p][3]\n",
    "    \n",
    "    scaler = X_scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    number_input_features = 7\n",
    "    def model_builder(hp):\n",
    "\n",
    "        hp_units = hp.Int('units', min_value=6, max_value=36, step=2)\n",
    "        hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "        hp_units2 = hp.Int('units2', min_value=3, max_value=18, step=2)\n",
    "        hp_activation2 = hp.Choice('activation2', values=['relu', 'tanh'])\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=hp_units, input_dim=number_input_features, activation=hp_activation))\n",
    "        model.add(Dense(units=hp_units2, activation=hp_activation2))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    tuner = kt.Hyperband(model_builder, objective='val_accuracy',\n",
    "                 max_epochs=100,\n",
    "                 factor=3,\n",
    "                 directory='./hp',\n",
    "                 project_name=f\"hp__reduced_{p}\")\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    print(f\"now running tuner search for {p}\")\n",
    "    tuner.search(X_train_scaled, y_train, epochs=100, validation_split=0.2, callbacks=[stop_early], verbose=0)\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_unit1 = best_hps.get('units')\n",
    "    best_unit2 = best_hps.get('units2') \n",
    "    best_activation1 =  best_hps.get('activation')\n",
    "    best_activation2 = best_hps.get('activation2')\n",
    "    best_learning_rate = best_hps.get('learning_rate')\n",
    "\n",
    "    best_dict = {'units1': best_unit1,\n",
    "                 'units2': best_unit2,\n",
    "                 'activation1': best_activation1,\n",
    "                 'activation2': best_activation2,\n",
    "                 'learning_rate': best_learning_rate}\n",
    "     \n",
    "    print(f\"best values for {p} are:\")\n",
    "    for k,v in best_dict.items():\n",
    "        print(k, v)\n",
    "\n",
    "    best_parameters = pd.DataFrame.from_dict(best_dict, orient='index', columns=[f\"{p}\"])\n",
    "    results_reduced = pd.concat([results_reduced, best_parameters], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb86a0a-25ff-4a39-b848-9aa192f6de07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c988d-de47-4f1a-89fd-f6a041ef2512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a7ef0-34d7-4aa7-a469-6fd3f4d3138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1715d-aa56-4e2a-a508-4c02a9a4d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd464d47-6bd4-470d-8f74-b26c1f268cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d71d9ca1-ce94-49d9-9bf4-664fb2bd7cb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24651f9e-befd-48d7-a988-bc66f4247344",
   "metadata": {},
   "source": [
    "## Use best parameters from tuning notebook to train one model per portfolio class for both the full and reduced feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749223c0-e99f-46af-8b11-d9b80ce163e7",
   "metadata": {},
   "source": [
    "### Full Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057a8d4-b6e7-46f1-a72c-a677b61e50a8",
   "metadata": {},
   "source": [
    "## *Conservative Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb703c7b-c1a6-466f-ad85-d847a9c5133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.9162 - accuracy: 0.5059 - 85ms/epoch - 11ms/step\n",
      "Loss: 0.9162380695343018, Accuracy: 0.5059288740158081\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'conservative']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'conservative']\n",
    "activation_1 = results_full.loc['activation1', 'conservative']\n",
    "activation_2 = results_full.loc['activation2', 'conservative']\n",
    "lr = results_full.loc['learning_rate', 'conservative']\n",
    "\n",
    "\n",
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_conservative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_conservative_scaled = X_scaler.transform(X_train_full_conservative)\n",
    "X_test_full_conservative_scaled = X_scaler.transform(X_test_full_conservative)\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_conservative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_conservative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_conservative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_full_conservative_scaled, y_test_conservative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a163e2-8926-480e-b4b6-45cb71a91f46",
   "metadata": {},
   "source": [
    "## *Balanced Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192b72d1-119f-460e-b58b-f8b5c142b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7331 - accuracy: 0.4901 - 87ms/epoch - 11ms/step\n",
      "Loss: 0.7330642342567444, Accuracy: 0.4901185631752014\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_balanced)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_balanced_scaled = X_scaler.transform(X_train_full_balanced)\n",
    "X_test_full_balanced_scaled = X_scaler.transform(X_test_full_balanced)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'balanced']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'balanced']\n",
    "activation_1 = results_full.loc['activation1', 'balanced']\n",
    "activation_2 = results_full.loc['activation2', 'balanced']\n",
    "lr = results_full.loc['learning_rate', 'balanced']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_balanced = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_balanced.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_balanced.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_full_balanced_scaled, y_test_balanced, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae2329-87bc-4499-98b8-3d963e35b26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19f33763-0668-431b-95c0-ca56ca94a4ec",
   "metadata": {},
   "source": [
    "## *Growth Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429921b6-fdd3-4b92-ae10-68c041ad7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.8730 - accuracy: 0.4900 - 90ms/epoch - 11ms/step\n",
      "Loss: 0.8729562163352966, Accuracy: 0.4900398552417755\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_growth)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_growth_scaled = X_scaler.transform(X_train_full_growth)\n",
    "X_test_full_growth_scaled = X_scaler.transform(X_test_full_growth)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'growth']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'growth']\n",
    "activation_1 = results_full.loc['activation1', 'growth']\n",
    "activation_2 = results_full.loc['activation2', 'growth']\n",
    "lr = results_full.loc['learning_rate', 'growth']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_growth = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_growth.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_growth.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_full_growth_scaled, y_test_growth, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c17114-71e2-4289-b81f-249908d1cb4f",
   "metadata": {},
   "source": [
    "## *Aggressive Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dc6a4b-2b7c-4c05-981f-116fd683c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.6990 - accuracy: 0.5339 - 100ms/epoch - 12ms/step\n",
      "Loss: 0.6989531517028809, Accuracy: 0.5338645577430725\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_aggressive)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_aggressive_scaled = X_scaler.transform(X_train_full_aggressive)\n",
    "X_test_full_aggressive_scaled = X_scaler.transform(X_test_full_aggressive)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'aggressive']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'aggressive']\n",
    "activation_1 = results_full.loc['activation1', 'aggressive']\n",
    "activation_2 = results_full.loc['activation2', 'aggressive']\n",
    "lr = results_full.loc['learning_rate', 'aggressive']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_aggressive = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_aggressive.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_aggressive.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_full_aggressive_scaled, y_test_aggressive, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84757b60-fdd1-414d-aa6b-f304caf0ac2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86119757-cb41-45b1-b564-1a99e05ea7c9",
   "metadata": {},
   "source": [
    "## Alternative Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1371932a-6738-4e65-92eb-8aa37b1efc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_alternative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_alternative_scaled = X_scaler.transform(X_train_full_alternative)\n",
    "X_test_full_alternative_scaled = X_scaler.transform(X_test_full_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea08b4e6-2222-4de8-afbd-9a4cdf8fd28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 2.2948 - accuracy: 0.4940 - 98ms/epoch - 12ms/step\n",
      "Loss: 2.294835329055786, Accuracy: 0.4940239191055298\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'alternative']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'alternative']\n",
    "activation_1 = results_full.loc['activation1', 'alternative']\n",
    "activation_2 = results_full.loc['activation2', 'alternative']\n",
    "lr = results_full.loc['learning_rate', 'alternative']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_alternative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_alternative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_alternative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_full_alternative_scaled, y_test_alternative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d725da9b-31bc-436f-988a-c0d7a5aab4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conservative Model\n",
      "Loss: 0.9162380695343018, Accuracy: 0.5059288740158081\n",
      "\n",
      "Balanced Model\n",
      "Loss: 0.7330642342567444, Accuracy: 0.4901185631752014\n",
      "\n",
      "Growth Model\n",
      "Loss: 0.8729562163352966, Accuracy: 0.4900398552417755\n",
      "\n",
      "Aggressive Model\n",
      "Loss: 0.6989531517028809, Accuracy: 0.5338645577430725\n",
      "\n",
      "Alternative Model\n",
      "Loss: 2.294835329055786, Accuracy: 0.4940239191055298\n"
     ]
    }
   ],
   "source": [
    "#Conservative Portfolio\n",
    "# deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_full_conservative_scaled, y_test_conservative, verbose=0)\n",
    "\n",
    "print(f\"\\nConservative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Balanced Portfolio\n",
    "# deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100)\n",
    "\n",
    "#Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_full_balanced_scaled, y_test_balanced, verbose=0)\n",
    "\n",
    "print(f\"\\nBalanced Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Growth Portfolio\n",
    "# deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100)\n",
    "\n",
    "#Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_full_growth_scaled, y_test_growth, verbose=0)\n",
    "\n",
    "print(f\"\\nGrowth Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Aggressive Portfolio\n",
    "# deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100)\n",
    "\n",
    "#Evaluate Aggressive Model using testing data\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_full_aggressive_scaled, y_test_aggressive, verbose=0)\n",
    "\n",
    "print(f\"\\nAggressive Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Alternative Portfolio\n",
    "# deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100)\n",
    "\n",
    "#Evaluate Alternative Model using testing data\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_full_alternative_scaled, y_test_alternative, verbose=0)\n",
    "\n",
    "print(f\"\\nAlternative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ee494-ab1c-44f9-bc2c-a9f91e17c3c6",
   "metadata": {},
   "source": [
    "### Make predictions using trained models. Save both class predicitions and prediction probabiities for evaluation score calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5526b79-1d35-4828-9dcd-1aee8b5f0eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 884us/step\n",
      "8/8 [==============================] - 0s 842us/step\n",
      "8/8 [==============================] - 0s 857us/step\n",
      "8/8 [==============================] - 0s 929us/step\n",
      "8/8 [==============================] - 0s 866us/step\n"
     ]
    }
   ],
   "source": [
    "full_alternative_proba = nn_alternative.predict(X_test_full_alternative_scaled)\n",
    "full_aggressive_proba = nn_aggressive.predict(X_test_full_aggressive_scaled)\n",
    "full_growth_proba = nn_growth.predict(X_test_full_growth_scaled)\n",
    "full_balanced_proba = nn_balanced.predict(X_test_full_balanced_scaled)\n",
    "full_conservative_proba = nn_conservative.predict(X_test_full_conservative_scaled)\n",
    "\n",
    "full_alternative_preds = tf.cast(full_alternative_proba >= 0.5, tf.int32)\n",
    "full_aggressive_preds = tf.cast(full_aggressive_proba >= 0.5, tf.int32)\n",
    "full_growth_preds = tf.cast(full_growth_proba >= 0.5, tf.int32)\n",
    "full_balanced_preds = tf.cast(full_balanced_proba >= 0.5, tf.int32)\n",
    "full_conservative_preds = tf.cast(full_conservative_proba >= 0.5, tf.int32)\n",
    "\n",
    "full_preds = {'alternative': [full_alternative_proba, full_alternative_preds],\n",
    "              'aggressive': [full_aggressive_proba, full_aggressive_preds],\n",
    "              'growth': [full_growth_proba, full_growth_preds],\n",
    "              'balanced': [full_balanced_proba, full_balanced_preds],\n",
    "              'conservative': [full_conservative_proba, full_conservative_preds]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1625d3-9741-459a-b8f3-503cb6711c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd248f-d75e-4a5f-be0f-5075049b98eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c91004-8425-4f41-83d5-ca723b2b0e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bf8ae-65e3-4cc4-af00-b07fa5a71b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "569b287a-37e1-4f48-8369-a7073b9e43b2",
   "metadata": {},
   "source": [
    "### Reduced Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fdda6-df30-4d45-92ba-bbaca5b38df5",
   "metadata": {},
   "source": [
    "## *Conservative Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe604bd-5953-40cd-85d5-dbc51ff13d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7118 - accuracy: 0.4941 - 88ms/epoch - 11ms/step\n",
      "Loss: 0.7117752432823181, Accuracy: 0.4940711557865143\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_conservative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_conservative_scaled = X_scaler.transform(X_train_reduced_conservative)\n",
    "X_test_reduced_conservative_scaled = X_scaler.transform(X_test_reduced_conservative)\n",
    "\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'conservative']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'conservative']\n",
    "activation_1 = results_reduced.loc['activation1', 'conservative']\n",
    "activation_2 = results_reduced.loc['activation2', 'conservative']\n",
    "lr = results_reduced.loc['learning_rate', 'conservative']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_conservative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_conservative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_conservative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "deep_net_conservative_model = nn_conservative.fit(X_train_reduced_conservative_scaled, y_train_conservative, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_reduced_conservative_scaled, y_test_conservative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2802a3c-f7be-48d7-ba3b-51217b9aa5c4",
   "metadata": {},
   "source": [
    "## *Balanced Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b534977d-d76f-496e-953a-cd29a6855f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.8205 - accuracy: 0.5375 - 86ms/epoch - 11ms/step\n",
      "Loss: 0.8204848170280457, Accuracy: 0.5375494360923767\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_balanced)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_balanced_scaled = X_scaler.transform(X_train_reduced_balanced)\n",
    "X_test_reduced_balanced_scaled = X_scaler.transform(X_test_reduced_balanced)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'balanced']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'balanced']\n",
    "activation_1 = results_reduced.loc['activation1', 'balanced']\n",
    "activation_2 = results_reduced.loc['activation2', 'balanced']\n",
    "lr = results_reduced.loc['learning_rate', 'balanced']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_balanced = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_balanced.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_balanced.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_balanced_model = nn_balanced.fit(X_train_reduced_balanced_scaled, y_train_balanced, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_reduced_balanced_scaled, y_test_balanced, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d6480-2919-4841-acc8-c64d37c5bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d744e0c-4935-471f-b077-a49a109909f9",
   "metadata": {},
   "source": [
    "## *Growth Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "627eeef1-a42e-47e5-8fa0-e9959e5f9b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7170 - accuracy: 0.5378 - 84ms/epoch - 11ms/step\n",
      "Loss: 0.716961145401001, Accuracy: 0.5378485918045044\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_growth)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_growth_scaled = X_scaler.transform(X_train_reduced_growth)\n",
    "X_test_reduced_growth_scaled = X_scaler.transform(X_test_reduced_growth)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'growth']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'growth']\n",
    "activation_1 = results_reduced.loc['activation1', 'growth']\n",
    "activation_2 = results_reduced.loc['activation2', 'growth']\n",
    "lr = results_reduced.loc['learning_rate', 'growth']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_growth = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_growth.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_growth.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_growth_model = nn_growth.fit(X_train_reduced_growth_scaled, y_train_growth, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_reduced_growth_scaled, y_test_growth, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f64ac-82e7-4c75-b012-d55977c6866a",
   "metadata": {},
   "source": [
    "## *Aggressive Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af15b3fd-1c41-4ca8-96d0-120b78b3f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7108 - accuracy: 0.4861 - 88ms/epoch - 11ms/step\n",
      "Loss: 0.7107688784599304, Accuracy: 0.48605579137802124\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_aggressive)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_aggressive_scaled = X_scaler.transform(X_train_reduced_aggressive)\n",
    "X_test_reduced_aggressive_scaled = X_scaler.transform(X_test_reduced_aggressive)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'aggressive']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'aggressive']\n",
    "activation_1 = results_reduced.loc['activation1', 'aggressive']\n",
    "activation_2 = results_reduced.loc['activation2', 'aggressive']\n",
    "lr = results_reduced.loc['learning_rate', 'aggressive']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_aggressive = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_aggressive.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_aggressive.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_aggressive_model = nn_aggressive.fit(X_train_reduced_aggressive_scaled, y_train_aggressive, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_reduced_aggressive_scaled, y_test_aggressive, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dc408-8d00-4f08-8ac5-755ab308d979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ab6ec9-4596-4b0b-bbcb-6154a727cf63",
   "metadata": {},
   "source": [
    "## Alternative Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eca1f350-df35-4498-b481-80b33d08d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_alternative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_alternative_scaled = X_scaler.transform(X_train_reduced_alternative)\n",
    "X_test_reduced_alternative_scaled = X_scaler.transform(X_test_reduced_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe9f915a-f8f3-4039-b803-e12f964de789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7026 - accuracy: 0.5418 - 92ms/epoch - 12ms/step\n",
      "Loss: 0.7026180624961853, Accuracy: 0.541832685470581\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'alternative']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'alternative']\n",
    "activation_1 = results_reduced.loc['activation1', 'alternative']\n",
    "activation_2 = results_reduced.loc['activation2', 'alternative']\n",
    "lr = results_reduced.loc['learning_rate', 'alternative']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_alternative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_alternative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_alternative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_alternative_model = nn_alternative.fit(X_train_reduced_alternative_scaled, y_train_alternative, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_reduced_alternative_scaled, y_test_alternative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da7bb63-6561-4c1a-9c16-d82e4dddfb63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conservative Model\n",
      "Loss: 0.7117752432823181, Accuracy: 0.4940711557865143\n",
      "\n",
      "Balanced Model\n",
      "Loss: 0.8204848170280457, Accuracy: 0.5375494360923767\n",
      "\n",
      "Growth Model\n",
      "Loss: 0.716961145401001, Accuracy: 0.5378485918045044\n",
      "\n",
      "Aggressive Model\n",
      "Loss: 0.7107688784599304, Accuracy: 0.48605579137802124\n",
      "\n",
      "Alternative Model\n",
      "Loss: 0.7026180624961853, Accuracy: 0.541832685470581\n"
     ]
    }
   ],
   "source": [
    "#Conservative Portfolio\n",
    "# deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_reduced_conservative_scaled, y_test_conservative, verbose=0)\n",
    "\n",
    "print(f\"\\nConservative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Balanced Portfolio\n",
    "# deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100)\n",
    "\n",
    "#Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_reduced_balanced_scaled, y_test_balanced, verbose=0)\n",
    "\n",
    "print(f\"\\nBalanced Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Growth Portfolio\n",
    "# deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100)\n",
    "\n",
    "#Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_reduced_growth_scaled, y_test_growth, verbose=0)\n",
    "\n",
    "print(f\"\\nGrowth Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Aggressive Portfolio\n",
    "# deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100)\n",
    "\n",
    "#Evaluate Aggressive Model using testing data\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_reduced_aggressive_scaled, y_test_aggressive, verbose=0)\n",
    "\n",
    "print(f\"\\nAggressive Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Alternative Portfolio\n",
    "# deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100)\n",
    "\n",
    "#Evaluate Alternative Model using testing data\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_reduced_alternative_scaled, y_test_alternative, verbose=0)\n",
    "\n",
    "print(f\"\\nAlternative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b23316-0595-479b-8c01-e2e54178325a",
   "metadata": {},
   "source": [
    "### Make predictions using trained models. Save both class predicitions and prediction probabiities for evaluation score calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe4a6bb-35f9-4fa8-a4cc-d2049c4b2b14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 881us/step\n",
      "8/8 [==============================] - 0s 908us/step\n",
      "8/8 [==============================] - 0s 846us/step\n",
      "8/8 [==============================] - 0s 840us/step\n",
      "8/8 [==============================] - 0s 906us/step\n"
     ]
    }
   ],
   "source": [
    "reduced_alternative_proba = nn_alternative.predict(X_test_reduced_alternative_scaled)\n",
    "reduced_aggressive_proba = nn_aggressive.predict(X_test_reduced_aggressive_scaled)\n",
    "reduced_growth_proba = nn_growth.predict(X_test_reduced_growth_scaled)\n",
    "reduced_balanced_proba = nn_balanced.predict(X_test_reduced_balanced_scaled)\n",
    "reduced_conservative_proba = nn_conservative.predict(X_test_reduced_conservative_scaled)\n",
    "\n",
    "reduced_alternative_preds = tf.cast(reduced_alternative_proba >= 0.5, tf.int32)\n",
    "reduced_aggressive_preds = tf.cast(reduced_aggressive_proba >= 0.5, tf.int32)\n",
    "reduced_growth_preds = tf.cast(reduced_growth_proba >= 0.5, tf.int32)\n",
    "reduced_balanced_preds = tf.cast(reduced_balanced_proba >= 0.5, tf.int32)\n",
    "reduced_conservative_preds = tf.cast(reduced_conservative_proba >= 0.5, tf.int32)\n",
    "\n",
    "reduced_preds = {'alternative': [reduced_alternative_proba, reduced_alternative_preds],\n",
    "              'aggressive': [reduced_aggressive_proba, reduced_aggressive_preds],\n",
    "              'growth': [reduced_growth_proba, reduced_growth_preds],\n",
    "              'balanced': [reduced_balanced_proba, reduced_balanced_preds],\n",
    "              'conservative': [reduced_conservative_proba, reduced_conservative_preds]\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa410e1-7f86-46a8-952a-9fe812e2a593",
   "metadata": {},
   "source": [
    "### compile tables of all evalutaion results for both full and reduced data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e99f2dd-3c63-471c-8268-841f838dbb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>reduced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conservative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.482531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.661376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">balanced</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.532177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.699229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">growth</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.528416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggressive</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.533167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.382775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alternative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.532402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.691689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             reduced\n",
       "type                                \n",
       "conservative roc_auc_score  0.482531\n",
       "             f1_score       0.661376\n",
       "balanced     roc_auc_score  0.532177\n",
       "             f1_score       0.699229\n",
       "growth       roc_auc_score  0.528416\n",
       "             f1_score       0.699482\n",
       "aggressive   roc_auc_score  0.533167\n",
       "             f1_score       0.382775\n",
       "alternative  roc_auc_score  0.532402\n",
       "             f1_score       0.691689"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_results = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    y_test = datafiles_reduced[p][3]\n",
    "    proba = reduced_preds[p][0]\n",
    "    preds = reduced_preds[p][1]\n",
    "    roc = roc_auc_score(y_test,proba)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    df = pd.DataFrame()\n",
    "    df.loc['roc_auc_score','reduced'] = roc\n",
    "    df.loc['f1_score', 'reduced'] = f1\n",
    "    df['type'] = p\n",
    "    reduced_results = pd.concat([reduced_results, df], axis=0)\n",
    "\n",
    "\n",
    "reduced_results.set_index('type', append=True, inplace=True)\n",
    "\n",
    "reduced_results = reduced_results.reorder_levels(['type',0])\n",
    "\n",
    "reduced_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b480072-18d1-4364-b757-025e129d721d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conservative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.485031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.472574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">balanced</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.458270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.614925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">growth</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.479949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.552448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggressive</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.530648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.696104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alternative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.535655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.257310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                full\n",
       "type                                \n",
       "conservative roc_auc_score  0.485031\n",
       "             f1_score       0.472574\n",
       "balanced     roc_auc_score  0.458270\n",
       "             f1_score       0.614925\n",
       "growth       roc_auc_score  0.479949\n",
       "             f1_score       0.552448\n",
       "aggressive   roc_auc_score  0.530648\n",
       "             f1_score       0.696104\n",
       "alternative  roc_auc_score  0.535655\n",
       "             f1_score       0.257310"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    y_test = datafiles_full[p][3]\n",
    "    proba = full_preds[p][0]\n",
    "    preds = full_preds[p][1]\n",
    "    roc = roc_auc_score(y_test,proba)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    df = pd.DataFrame()\n",
    "    df.loc['roc_auc_score','full'] = roc\n",
    "    df.loc['f1_score', 'full'] = f1\n",
    "    df['type'] = p\n",
    "    full_results = pd.concat([full_results, df], axis=0)\n",
    "\n",
    "\n",
    "full_results.set_index('type', append=True, inplace=True)\n",
    "\n",
    "full_results = full_results.reorder_levels(['type',0])\n",
    "full_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3eeb3-a8ab-4254-a484-bf758d5c3134",
   "metadata": {},
   "source": [
    "### combine full and reduced data evalutionas into one table for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01780ac9-66c6-4318-b9c5-ec2d517d0196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = pd.concat([full_results, reduced_results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f15ac57-7167-4f33-a62e-477d72aee987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6d207_row0_col0, #T_6d207_row1_col1, #T_6d207_row2_col1, #T_6d207_row3_col1, #T_6d207_row4_col1, #T_6d207_row5_col1, #T_6d207_row6_col1, #T_6d207_row7_col0, #T_6d207_row8_col0, #T_6d207_row9_col1 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6d207\">\n",
       "  <caption>Metrics Comparison for All Models</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6d207_level0_col0\" class=\"col_heading level0 col0\" >full</th>\n",
       "      <th id=\"T_6d207_level0_col1\" class=\"col_heading level0 col1\" >reduced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >type</th>\n",
       "      <th class=\"index_name level1\" >&nbsp;</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">conservative</th>\n",
       "      <th id=\"T_6d207_level1_row0\" class=\"row_heading level1 row0\" >roc_auc_score</th>\n",
       "      <td id=\"T_6d207_row0_col0\" class=\"data row0 col0\" >0.485031</td>\n",
       "      <td id=\"T_6d207_row0_col1\" class=\"data row0 col1\" >0.482531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level1_row1\" class=\"row_heading level1 row1\" >f1_score</th>\n",
       "      <td id=\"T_6d207_row1_col0\" class=\"data row1 col0\" >0.472574</td>\n",
       "      <td id=\"T_6d207_row1_col1\" class=\"data row1 col1\" >0.661376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">balanced</th>\n",
       "      <th id=\"T_6d207_level1_row2\" class=\"row_heading level1 row2\" >roc_auc_score</th>\n",
       "      <td id=\"T_6d207_row2_col0\" class=\"data row2 col0\" >0.458270</td>\n",
       "      <td id=\"T_6d207_row2_col1\" class=\"data row2 col1\" >0.532177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level1_row3\" class=\"row_heading level1 row3\" >f1_score</th>\n",
       "      <td id=\"T_6d207_row3_col0\" class=\"data row3 col0\" >0.614925</td>\n",
       "      <td id=\"T_6d207_row3_col1\" class=\"data row3 col1\" >0.699229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"2\">growth</th>\n",
       "      <th id=\"T_6d207_level1_row4\" class=\"row_heading level1 row4\" >roc_auc_score</th>\n",
       "      <td id=\"T_6d207_row4_col0\" class=\"data row4 col0\" >0.479949</td>\n",
       "      <td id=\"T_6d207_row4_col1\" class=\"data row4 col1\" >0.528416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level1_row5\" class=\"row_heading level1 row5\" >f1_score</th>\n",
       "      <td id=\"T_6d207_row5_col0\" class=\"data row5 col0\" >0.552448</td>\n",
       "      <td id=\"T_6d207_row5_col1\" class=\"data row5 col1\" >0.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"2\">aggressive</th>\n",
       "      <th id=\"T_6d207_level1_row6\" class=\"row_heading level1 row6\" >roc_auc_score</th>\n",
       "      <td id=\"T_6d207_row6_col0\" class=\"data row6 col0\" >0.530648</td>\n",
       "      <td id=\"T_6d207_row6_col1\" class=\"data row6 col1\" >0.533167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level1_row7\" class=\"row_heading level1 row7\" >f1_score</th>\n",
       "      <td id=\"T_6d207_row7_col0\" class=\"data row7 col0\" >0.696104</td>\n",
       "      <td id=\"T_6d207_row7_col1\" class=\"data row7 col1\" >0.382775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"2\">alternative</th>\n",
       "      <th id=\"T_6d207_level1_row8\" class=\"row_heading level1 row8\" >roc_auc_score</th>\n",
       "      <td id=\"T_6d207_row8_col0\" class=\"data row8 col0\" >0.535655</td>\n",
       "      <td id=\"T_6d207_row8_col1\" class=\"data row8 col1\" >0.532402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d207_level1_row9\" class=\"row_heading level1 row9\" >f1_score</th>\n",
       "      <td id=\"T_6d207_row9_col0\" class=\"data row9 col0\" >0.257310</td>\n",
       "      <td id=\"T_6d207_row9_col1\" class=\"data row9 col1\" >0.691689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17344a5e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.style.highlight_max(color='lightblue', axis = 1).set_caption(\"Metrics Comparison for All Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75dcbf-2f0f-47aa-9dbb-42ca6a16c307",
   "metadata": {},
   "source": [
    "### save evalution results for 'best' model to a csv for use in comparing evalutaion results of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74316961-c73a-4b5c-9a7d-3b95f79994fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = all_results[['reduced']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c943383-4b26-47f9-a2bf-17ec0e2c50cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f65f23-2c1e-442a-b993-76ec66876a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best.to_csv(Path(\"./model_metrics/nn.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b89598-26e2-4739-bb31-e3651af20075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e8186-d5bc-4c46-9c4d-b218673094e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
